{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 5 days of Data Cleaning challenge.\n\n## Day 5 : Inconsistant data-entry\n\nHere's what we're going to do today:\n\n* [Get our environment set up](#1)\n* [Do some preliminary text pre-processing](#2)\n* [Use fuzzy matching to correct inconsistent data entry](#3)\n\nLet's get started!\n\n[Data for Pakistan Suicide Bombing Attack](https://www.kaggle.com/zusmani/pakistansuicideattacks)"},{"metadata":{},"cell_type":"markdown","source":"## Getting our environment setup<a id=\"1\"></a>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport fuzzywuzzy\nfrom fuzzywuzzy import process\nimport chardet\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/pakistansuicideattacks/PakistanSuicideAttacks Ver 6 (10-October-2017).csv\n/kaggle/input/pakistansuicideattacks/PakistanSuicideAttacks Ver 11 (30-November-2017).csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"When I tried to read in the PakistanSuicideAttacks Ver 11 (30-November-2017).csvfile the first time, I got a character encoding error, so I'm going to quickly check out what the encoding should be..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at the first 100000 bytes to guess the character encoding\nwith open(\"/kaggle/input/pakistansuicideattacks/PakistanSuicideAttacks Ver 11 (30-November-2017).csv\", \"rb\") as rawdata:\n    result = chardet.detect(rawdata.read(100000))\n    \n# check what the chaacter encoding might be\nprint(result)","execution_count":2,"outputs":[{"output_type":"stream","text":"{'encoding': 'Windows-1252', 'confidence': 0.73, 'language': ''}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/pakistansuicideattacks/PakistanSuicideAttacks Ver 11 (30-November-2017).csv\", encoding = \"Windows-1252\")","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Do some preliminary text preprocessing<a id=\"2\"></a>\n Take a moment here to look at the data and get familiar with it. :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"Index(['S#', 'Date', 'Islamic Date', 'Blast Day Type', 'Holiday Type', 'Time',\n       'City', 'Latitude', 'Longitude', 'Province', 'Location',\n       'Location Category', 'Location Sensitivity', 'Open/Closed Space',\n       'Influencing Event/Event', 'Target Type', 'Targeted Sect if any',\n       'Killed Min', 'Killed Max', 'Injured Min', 'Injured Max',\n       'No. of Suicide Blasts', 'Explosive Weight (max)', 'Hospital Names',\n       'Temperature(C)', 'Temperature(F)'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   S#                     Date                   Islamic Date Blast Day Type  \\\n0   1  Sunday-November 19-1995  25 Jumaada al-THaany 1416 A.H        Holiday   \n1   2   Monday-November 6-2000           10 SHa`baan 1421 A.H    Working Day   \n2   3     Wednesday-May 8-2002              25 safar 1423 A.H    Working Day   \n3   4      Friday-June 14-2002     3 Raby` al-THaany 1423 A.H    Working Day   \n4   5       Friday-July 4-2003     4 Jumaada al-awal 1424 A.H    Working Day   \n\n  Holiday Type         Time       City  Latitude Longitude     Province  ...  \\\n0      Weekend          NaN  Islamabad   33.7180   73.0718      Capital  ...   \n1          NaN          NaN    Karachi   24.9918   66.9911        Sindh  ...   \n2          NaN      7:45 AM   Karachi    24.9918   66.9911        Sindh  ...   \n3          NaN  11:10:00 AM    Karachi   24.9918   66.9911        Sindh  ...   \n4          NaN          NaN     Quetta   30.2095   67.0182  Baluchistan  ...   \n\n  Targeted Sect if any Killed Min Killed Max Injured Min Injured Max  \\\n0                 None       14.0       15.0         NaN          60   \n1                 None        NaN        3.0         NaN           3   \n2            Christian       13.0       15.0        20.0          40   \n3            Christian        NaN       12.0         NaN          51   \n4               Shiite       44.0       47.0         NaN          65   \n\n  No. of Suicide Blasts Explosive Weight (max)  \\\n0                   2.0                    NaN   \n1                   1.0                    NaN   \n2                   1.0                 2.5 Kg   \n3                   1.0                    NaN   \n4                   1.0                    NaN   \n\n                                      Hospital Names  Temperature(C)  \\\n0                                                NaN          15.835   \n1                                                NaN          23.770   \n2  1.Jinnah Postgraduate Medical Center 2. Civil ...          31.460   \n3                                                NaN          31.430   \n4  1.CMH Quetta \\n2.Civil Hospital 3. Boland Medi...          33.120   \n\n   Temperature(F)  \n0          60.503  \n1          74.786  \n2          88.628  \n3          88.574  \n4          91.616  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>S#</th>\n      <th>Date</th>\n      <th>Islamic Date</th>\n      <th>Blast Day Type</th>\n      <th>Holiday Type</th>\n      <th>Time</th>\n      <th>City</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>Province</th>\n      <th>...</th>\n      <th>Targeted Sect if any</th>\n      <th>Killed Min</th>\n      <th>Killed Max</th>\n      <th>Injured Min</th>\n      <th>Injured Max</th>\n      <th>No. of Suicide Blasts</th>\n      <th>Explosive Weight (max)</th>\n      <th>Hospital Names</th>\n      <th>Temperature(C)</th>\n      <th>Temperature(F)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Sunday-November 19-1995</td>\n      <td>25 Jumaada al-THaany 1416 A.H</td>\n      <td>Holiday</td>\n      <td>Weekend</td>\n      <td>NaN</td>\n      <td>Islamabad</td>\n      <td>33.7180</td>\n      <td>73.0718</td>\n      <td>Capital</td>\n      <td>...</td>\n      <td>None</td>\n      <td>14.0</td>\n      <td>15.0</td>\n      <td>NaN</td>\n      <td>60</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.835</td>\n      <td>60.503</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Monday-November 6-2000</td>\n      <td>10 SHa`baan 1421 A.H</td>\n      <td>Working Day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Karachi</td>\n      <td>24.9918</td>\n      <td>66.9911</td>\n      <td>Sindh</td>\n      <td>...</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23.770</td>\n      <td>74.786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Wednesday-May 8-2002</td>\n      <td>25 safar 1423 A.H</td>\n      <td>Working Day</td>\n      <td>NaN</td>\n      <td>7:45 AM</td>\n      <td>Karachi</td>\n      <td>24.9918</td>\n      <td>66.9911</td>\n      <td>Sindh</td>\n      <td>...</td>\n      <td>Christian</td>\n      <td>13.0</td>\n      <td>15.0</td>\n      <td>20.0</td>\n      <td>40</td>\n      <td>1.0</td>\n      <td>2.5 Kg</td>\n      <td>1.Jinnah Postgraduate Medical Center 2. Civil ...</td>\n      <td>31.460</td>\n      <td>88.628</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Friday-June 14-2002</td>\n      <td>3 Raby` al-THaany 1423 A.H</td>\n      <td>Working Day</td>\n      <td>NaN</td>\n      <td>11:10:00 AM</td>\n      <td>Karachi</td>\n      <td>24.9918</td>\n      <td>66.9911</td>\n      <td>Sindh</td>\n      <td>...</td>\n      <td>Christian</td>\n      <td>NaN</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>51</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>31.430</td>\n      <td>88.574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Friday-July 4-2003</td>\n      <td>4 Jumaada al-awal 1424 A.H</td>\n      <td>Working Day</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Quetta</td>\n      <td>30.2095</td>\n      <td>67.0182</td>\n      <td>Baluchistan</td>\n      <td>...</td>\n      <td>Shiite</td>\n      <td>44.0</td>\n      <td>47.0</td>\n      <td>NaN</td>\n      <td>65</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.CMH Quetta \\n2.Civil Hospital 3. Boland Medi...</td>\n      <td>33.120</td>\n      <td>91.616</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 26 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For this exercise, I'm interested in cleaning up the \"City\" column to make sure there's no data entry inconsistencies in it. We could go through and check each row by hand, of course, and hand-correct inconsistencies when we find them. There's a more efficient way to do this though!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the unique values in the 'City' column\ncities = df['City'].unique()\n\n# sort then in alphabetically and then take a closer look\ncities.sort()\ncities","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"array(['ATTOCK', 'Attock ', 'Bajaur Agency', 'Bannu', 'Bhakkar ', 'Buner',\n       'Chakwal ', 'Chaman', 'Charsadda', 'Charsadda ', 'D. I Khan',\n       'D.G Khan', 'D.G Khan ', 'D.I Khan', 'D.I Khan ', 'Dara Adam Khel',\n       'Dara Adam khel', 'Fateh Jang', 'Ghallanai, Mohmand Agency ',\n       'Gujrat', 'Hangu', 'Haripur', 'Hayatabad', 'Islamabad',\n       'Islamabad ', 'Jacobabad', 'KURRAM AGENCY', 'Karachi', 'Karachi ',\n       'Karak', 'Khanewal', 'Khuzdar', 'Khyber Agency', 'Khyber Agency ',\n       'Kohat', 'Kohat ', 'Kuram Agency ', 'Lahore', 'Lahore ',\n       'Lakki Marwat', 'Lakki marwat', 'Lasbela', 'Lower Dir', 'MULTAN',\n       'Malakand ', 'Mansehra', 'Mardan', 'Mohmand Agency',\n       'Mohmand Agency ', 'Mohmand agency', 'Mosal Kor, Mohmand Agency',\n       'Multan', 'Muzaffarabad', 'North Waziristan', 'North waziristan',\n       'Nowshehra', 'Orakzai Agency', 'Peshawar', 'Peshawar ', 'Pishin',\n       'Poonch', 'Quetta', 'Quetta ', 'Rawalpindi', 'Sargodha',\n       'Sehwan town', 'Shabqadar-Charsadda', 'Shangla ', 'Shikarpur',\n       'Sialkot', 'South Waziristan', 'South waziristan', 'Sudhanoti',\n       'Sukkur', 'Swabi ', 'Swat', 'Swat ', 'Taftan',\n       'Tangi, Charsadda District', 'Tank', 'Tank ', 'Taunsa',\n       'Tirah Valley', 'Totalai', 'Upper Dir', 'Wagah', 'Zhob', 'bannu',\n       'karachi', 'karachi ', 'lakki marwat', 'peshawar', 'swat'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['City'].nunique()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"93"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Just looking at this, I can see some problems due to inconsistent data entry: 'Lahore' and 'Lahore ', for example, or 'Lakki Marwat' and 'Lakki marwat'.\n\nThe first thing I'm going to do is make everything lower case (I can change it back at the end if I like) and remove any white spaces at the beginning and end of cells. Inconsistencies in capitalizations and trailing white spaces are very common in text data and you can fix a good 80% of your text data entry inconsistencies by doing this."},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to lower case\ndf['City'] = df['City'].str.lower()\n\n# removing trailing white spaces\ndf['City'] = df['City'].str.strip()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the unique values in the 'City' column after converting in lower case and removing white spaces\ncities = df['City'].unique()\n\n# sort then in alphabetically and then take a closer look\ncities.sort()\ncities","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n       'chaman', 'charsadda', 'd. i khan', 'd.g khan', 'd.i khan',\n       'dara adam khel', 'fateh jang', 'ghallanai, mohmand agency',\n       'gujrat', 'hangu', 'haripur', 'hayatabad', 'islamabad',\n       'jacobabad', 'karachi', 'karak', 'khanewal', 'khuzdar',\n       'khyber agency', 'kohat', 'kuram agency', 'kurram agency',\n       'lahore', 'lakki marwat', 'lasbela', 'lower dir', 'malakand',\n       'mansehra', 'mardan', 'mohmand agency',\n       'mosal kor, mohmand agency', 'multan', 'muzaffarabad',\n       'north waziristan', 'nowshehra', 'orakzai agency', 'peshawar',\n       'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['City'].nunique()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"67"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Now we have 67 unique values in `City` column. We have eliminated 26 duplicate/inconsistant values.\n\nNow we'll take a look at all the unique values in the `Province` column."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the unique values in the `Province` column\nprovinces = df['Province'].unique()\n\n# sort them alphabetically and then take a closer look\nprovinces.sort()\nprovinces","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"array(['AJK', 'Balochistan', 'Baluchistan', 'Capital', 'FATA', 'Fata',\n       'KPK', 'Punjab', 'Sindh'], dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Province'].nunique()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"9"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Inconsistent data entry: 'Balochistan' and 'Baluchistan', 'FATA' and 'Fata'."},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert to lower case\ndf['Province']  = df['Province'].str.lower()\n\n# removing trailing white spaces\ndf['Province']  = df['Province'].str.strip()","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the unique values in the `Province` column after converting in lower case and removing white spaces\nprovinces = df['Province'].unique()\n\n# sort them alphabetically and then take a closer look\nprovinces.sort()\nprovinces","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"array(['ajk', 'balochistan', 'baluchistan', 'capital', 'fata', 'kpk',\n       'punjab', 'sindh'], dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Province'].nunique()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"8"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Use fuzzy matching to correct inconsistent data entry<a id=\"3\"></a>\nAlright, let's take another look at the city column and see if there's any more data cleaning we need to do."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the unique values in the 'City' column\ncities = df['City'].unique()\n\n# sort then in alphabetically and then take a closer look\ncities.sort()\ncities","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n       'chaman', 'charsadda', 'd. i khan', 'd.g khan', 'd.i khan',\n       'dara adam khel', 'fateh jang', 'ghallanai, mohmand agency',\n       'gujrat', 'hangu', 'haripur', 'hayatabad', 'islamabad',\n       'jacobabad', 'karachi', 'karak', 'khanewal', 'khuzdar',\n       'khyber agency', 'kohat', 'kuram agency', 'kurram agency',\n       'lahore', 'lakki marwat', 'lasbela', 'lower dir', 'malakand',\n       'mansehra', 'mardan', 'mohmand agency',\n       'mosal kor, mohmand agency', 'multan', 'muzaffarabad',\n       'north waziristan', 'nowshehra', 'orakzai agency', 'peshawar',\n       'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It does look like there are some remaining inconsistencies: 'd. i khan' and 'd.i khan' should probably be the same. (I looked it up and 'd.g khan' is a seperate city, so I shouldn't combine those.)\n\nI'm going to use the [fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy) package to help identify which string are closest to each other. This dataset is small enough that we could probably could correct errors by hand, but that approach doesn't scale well. (Would you want to correct a thousand errors by hand? What about ten thousand? Automating things as early as possible is generally a good idea. Plus, itâ€™s fun! :)\n\n**Fuzzy matching :** The process of automatically finding text strings that are very similar to the target string. In general, a string is considered \"closer\" to another one the fewer characters you'd need to change if you were transforming one string into another. So \"apple\" and \"snapple\" are two changes away from each other (add \"s\" and \"n\") while \"in\" and \"on\" and one change away (rplace \"i\" with \"o\"). You won't always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.\n\nFuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we're going to get the ten strings from our list of cities that have the closest distance to \"d.i khan\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the top ten closest matches to \"d.i khan\"\nmatches = fuzzywuzzy.process.extract(\"d.i khan\", cities, limit = 10, scorer = fuzzywuzzy.fuzz.token_sort_ratio)\n\n# take a look at them\nmatches","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"[('d. i khan', 100),\n ('d.i khan', 100),\n ('d.g khan', 88),\n ('khanewal', 50),\n ('sudhanoti', 47),\n ('hangu', 46),\n ('kohat', 46),\n ('dara adam khel', 45),\n ('chaman', 43),\n ('mardan', 43)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"We can see that two of the items in the cities are very close to \"d.i khan\": \"d. i khan\" and \"d.i khan\". We can also see the \"d.g khan\", which is a seperate city, has a ratio of 88. Since we don't want to replace \"d.g khan\" with \"d.i khan\", let's replace all rows in our City column that have a ratio of > 90 with \"d. i khan\".\n\nTo do this, I'm going to write a function. (It's a good idea to write a general purpose function you can reuse if you think you might have to do a specific task more than once or twice. This keeps you from having to copy and paste code too often, which saves time and can help prevent mistakes.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to replace rows in the provided column of the provided dataframe that match the provided string above the provided ratio with the provided string\ndef replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n    \n    # get the list of unique strings\n    strings = df[column].unique()\n    \n    # get the top 10 closest matches to our input string\n    matches = fuzzywuzzy.process.extract(string_to_match, strings, limit = 10, scorer = fuzzywuzzy.fuzz.token_sort_ratio)\n    \n    # only get matches with a ratio > 90\n    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n    \n    # get the rows of all the close matches in our dataframe\n    rows_with_matches = df[column].isin(close_matches)\n    \n    # replace all rows with close matches with the input matches\n    df.loc[rows_with_matches, column] = string_to_match\n    \n    # let us know the function's done\n    print(\"All done!\")","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have a function, we can put  it into the test!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# use the function we just wrote to replace close matches to \"d.i khan\" with \"d.i khan\"\nreplace_matches_in_column(df = df, column = \"City\", string_to_match = \"d.i khan\")","execution_count":19,"outputs":[{"output_type":"stream","text":"All done!\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"And now let's ckeck the unique values in our `City` column again and make sure we've tidied up `d.i khan` correctly."},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the unique values in the 'City' column\ncities = df['City'].unique()\n\n# sort them alphabetically and then take a closer look\ncities.sort()\ncities","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n       'chaman', 'charsadda', 'd.g khan', 'd.i khan', 'dara adam khel',\n       'fateh jang', 'ghallanai, mohmand agency', 'gujrat', 'hangu',\n       'haripur', 'hayatabad', 'islamabad', 'jacobabad', 'karachi',\n       'karak', 'khanewal', 'khuzdar', 'khyber agency', 'kohat',\n       'kuram agency', 'kurram agency', 'lahore', 'lakki marwat',\n       'lasbela', 'lower dir', 'malakand', 'mansehra', 'mardan',\n       'mohmand agency', 'mosal kor, mohmand agency', 'multan',\n       'muzaffarabad', 'north waziristan', 'nowshehra', 'orakzai agency',\n       'peshawar', 'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It looks like 'kuram agency' and 'kurram agency' should be the same city.\nreplace_matches_in_column(df = df, column = \"City\", string_to_match = 'kuram agency')","execution_count":22,"outputs":[{"output_type":"stream","text":"All done!\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Let's again check the city column for 'kuram agency'"},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the unique values in the 'City' column\ncities = df['City'].unique()\n\n# sort them alphabetically and then take a closer look\ncities.sort()\ncities","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"array(['attock', 'bajaur agency', 'bannu', 'bhakkar', 'buner', 'chakwal',\n       'chaman', 'charsadda', 'd.g khan', 'd.i khan', 'dara adam khel',\n       'fateh jang', 'ghallanai, mohmand agency', 'gujrat', 'hangu',\n       'haripur', 'hayatabad', 'islamabad', 'jacobabad', 'karachi',\n       'karak', 'khanewal', 'khuzdar', 'khyber agency', 'kohat',\n       'kuram agency', 'lahore', 'lakki marwat', 'lasbela', 'lower dir',\n       'malakand', 'mansehra', 'mardan', 'mohmand agency',\n       'mosal kor, mohmand agency', 'multan', 'muzaffarabad',\n       'north waziristan', 'nowshehra', 'orakzai agency', 'peshawar',\n       'pishin', 'poonch', 'quetta', 'rawalpindi', 'sargodha',\n       'sehwan town', 'shabqadar-charsadda', 'shangla', 'shikarpur',\n       'sialkot', 'south waziristan', 'sudhanoti', 'sukkur', 'swabi',\n       'swat', 'taftan', 'tangi, charsadda district', 'tank', 'taunsa',\n       'tirah valley', 'totalai', 'upper dir', 'wagah', 'zhob'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# province column \n\n# get all the unique values in the `Province` column after converting in lower case and removing white spaces\nprovinces = df['Province'].unique()\n\n# sort them alphabetically and then take a closer look\nprovinces.sort()\nprovinces","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"array(['ajk', 'balochistan', 'baluchistan', 'capital', 'fata', 'kpk',\n       'punjab', 'sindh'], dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"`balochistan` and `baluchistan` looks similar. Let's replace all rows in our Provicnce column that have a ratio of > 90 with `baluchistan`."},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_matches_in_column(df = df, column = \"Province\", string_to_match = \"baluchistan\")","execution_count":27,"outputs":[{"output_type":"stream","text":"All done!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all the unique values in the `Province` column after converting in lower case and removing white spaces\nprovinces = df['Province'].unique()\n\n# sort them alphabetically and then take a closer look\nprovinces.sort()\nprovinces","execution_count":28,"outputs":[{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"array(['ajk', 'baluchistan', 'capital', 'fata', 'kpk', 'punjab', 'sindh'],\n      dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Hurryyy! we have done the replacements. :D"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}